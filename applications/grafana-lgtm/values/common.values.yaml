---
grafana:
  # -- Deploy Grafana if enabled. See [upstream readme](https://github.com/grafana/helm-charts/tree/main/charts/grafana#configuration) for full values reference.
  enabled: true

  admin:
    existingSecret: grafana-admin
    userKey: username
    passwordKey: password
  
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          folderUid: 'default'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
        - name: 'gatewayapistate'
          orgId: 1
          folder: 'Gateway API State'
          folderUid: 'gateway-api-state'
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/gatewayapistate
  
  dashboards:
    gatewayapistate:
      gatewayclasses:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/gatewayclasses.json
        datasource: Mimir
      gateways:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/gateways.json
        datasource: Mimir
      grpcroutes:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/grpcroutes.json
        datasource: Mimir
      httproutes:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/httproutes.json
        datasource: Mimir
      tcproutes:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/tcproutes.json
        datasource: Mimir
      udproutes:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/udproutes.json
        datasource: Mimir
      tlsroutes:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/gateway-api-state/tlsroutes.json
        datasource: Mimir
    default:
      # https://grafana.com/grafana/dashboards/11022-envoy-global/
      envoy-global:
        gnetId: 11022
        revision: 1
        datasource: Mimir
      # https://grafana.com/grafana/dashboards/6693-envoy-proxy/
      envoy-proxy:
        gnetId: 6693
        revision: 1
        datasource: Mimir
      # https://grafana.com/grafana/dashboards/11021-envoy-clusters/
      envoy-clusters:
        gnetId: 11021
        revision: 1
        datasource: Mimir
      # https://grafana.com/grafana/dashboards/20842-cert-manager-kubernetes/
      cert-manager:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/cert-manager.json
        datasource: Mimir
      external-dns:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/external-dns.json
        datasource: Mimir
      onepassword-operator:
        url: https://raw.githubusercontent.com/estenrye/cd-homelab/a163e774aedaf6275fb21d4644b7aabff36dc72c/infrastructure/rackspace-spot/remote-backend/tf-workload/dashboards/1password.json
        datasource: Mimir

  # -- Grafana data sources config. Connects to all three by default
  datasources:
    datasources.yaml:
      apiVersion: 1
      # -- Datasources linked to the Grafana instance. Override if you disable any components.
      datasources:
        # https://grafana.com/docs/grafana/latest/datasources/loki/#provision-the-loki-data-source
        - name: Loki
          uid: loki
          type: loki
          url: http://{{ .Release.Name }}-loki-gateway
          isDefault: false
        # https://grafana.com/docs/grafana/latest/datasources/prometheus/#provision-the-data-source
        - name: Mimir
          uid: prom
          type: prometheus
          url: http://{{ .Release.Name }}-mimir-nginx/prometheus
          isDefault: true
        # https://grafana.com/docs/grafana/latest/datasources/tempo/configure-tempo-data-source/#provision-the-data-source
        - name: Tempo
          uid: tempo
          type: tempo
          url: http://{{ .Release.Name }}-tempo-query-frontend:3100
          isDefault: false
          jsonData:
            tracesToLogsV2:
              datasourceUid: loki
            lokiSearch:
              datasourceUid: loki
            tracesToMetrics:
              datasourceUid: prom
            serviceMap:
              datasourceUid: prom
        - name: Pyroscope
          uid: pyroscope
          type: pyroscope
          url: http://pyroscope-query-frontend:4040
          isDefault: false
          jsonData:
            querying:
              backendType: Phlare

loki:
  # -- Deploy Loki if enabled. See [upstream readme](https://github.com/grafana/helm-charts/tree/main/charts/loki-distributed#values) for full values reference.
  enabled: true
  global:
    extraEnvFrom:
      - secretRef:
          name: s3-bucket-credentials

  storage:
    bucket_names:
      chunks:  rye-ninja-loki-chunks
      ruler:   rye-ninja-loki-ruler
      admin:   rye-ninja-loki-admin
    type: s3
    s3:
      endpoint: s3.us-central-1.wasabisys.com
      region: us-central-1
# -- Mimir chart values. Resources are set to a minimum by default.
mimir:
  # -- Deploy Mimir if enabled. See [upstream values.yaml](https://github.com/grafana/mimir/blob/main/operations/helm/charts/mimir-distributed/values.yaml) for full values reference.
  enabled: true
  global:
    extraEnvFrom:
      - secretRef:
          name: s3-bucket-credentials
  config: |
    usage_stats:
      installation_mode: helm

    activity_tracker:
      filepath: /active-query-tracker/activity.log

    alertmanager:
      data_dir: /data
      enable_api: true
      external_url: /alertmanager
      fallback_config_file: /configs/alertmanager_fallback_config.yaml

    alertmanager_storage:
      backend: s3
      s3:
        access_key_id: ${AWS_ACCESS_KEY_ID}
        bucket_name: ${S3_BUCKET_NAME_PREFIX}-alert-manager
        endpoint: ${S3_ENDPOINT}
        insecure: false
        secret_access_key: ${AWS_SECRET_ACCESS_KEY}

    # This configures how the store-gateway synchronizes blocks stored in the bucket. It uses Minio by default for getting started (configured via flags) but this should be changed for production deployments.
    blocks_storage:
      backend: s3
      bucket_store:
        sync_dir: /data/tsdb-sync
      s3:
        access_key_id: ${AWS_ACCESS_KEY_ID}
        bucket_name: ${S3_BUCKET_NAME_PREFIX}-blocks-storage
        endpoint: ${S3_ENDPOINT}
        insecure: false
        secret_access_key: ${AWS_SECRET_ACCESS_KEY}
      tsdb:
        dir: /data/tsdb
        head_compaction_interval: 15m
        wal_replay_concurrency: 3

    compactor:
      compaction_interval: 30m
      deletion_delay: 2h
      max_closing_blocks_concurrency: 2
      max_opening_blocks_concurrency: 4
      symbols_flushers_concurrency: 4
      first_level_compaction_wait_period: 25m
      data_dir: "/data"
      sharding_ring:
        wait_stability_min_duration: 1m
        heartbeat_period: 1m
        heartbeat_timeout: 4m

    distributor:
      ring:
        heartbeat_period: 1m
        heartbeat_timeout: 4m

    frontend:
      parallelize_shardable_queries: true
      scheduler_address: lgtm-mimir-query-scheduler-headless.grafana-lgtm.svc:9095

    frontend_worker:
      grpc_client_config:
        max_send_msg_size: 419430400 # 400MiB
      scheduler_address: lgtm-mimir-query-scheduler-headless.grafana-lgtm.svc:9095

    ingester:
      ring:
        final_sleep: 0s
        num_tokens: 512
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false
        heartbeat_period: 2m
        heartbeat_timeout: 10m

    ingester_client:
      grpc_client_config:
        max_recv_msg_size: 104857600
        max_send_msg_size: 104857600

    limits:
      # Limit queries to 500 days. You can override this on a per-tenant basis.
      max_total_query_length: 12000h
      # Adjust max query parallelism to 16x sharding, without sharding we can run 15d queries fully in parallel.
      # With sharding we can further shard each day another 16 times. 15 days * 16 shards = 240 subqueries.
      max_query_parallelism: 240
      # Avoid caching results newer than 10m because some samples can be delayed
      # This presents caching incomplete results
      max_cache_freshness: 10m

    memberlist:
      abort_if_cluster_join_fails: false
      compression_enabled: false
      join_members:
      - dns+lgtm-mimir-gossip-ring.grafana-lgtm.svc.cluster.local.:7946

    querier:
      # With query sharding we run more but smaller queries. We must strike a balance
      # which allows us to process more sharded queries in parallel when requested, but not overload
      # queriers during non-sharded queries.
      max_concurrent: 16

    query_scheduler:
      # Increase from default of 100 to account for queries created by query sharding
      max_outstanding_requests_per_tenant: 800

    ruler:
      alertmanager_url: dnssrvnoa+http://_http-metrics._tcp.lgtm-mimir-alertmanager-headless.grafana-lgtm.svc.cluster.local./alertmanager
      enable_api: true
      rule_path: /data

    ruler_storage:
      backend: s3
      s3:
        access_key_id: ${AWS_ACCESS_KEY_ID}
        bucket_name: ${S3_BUCKET_NAME_PREFIX}-ruler-storage
        endpoint: ${S3_ENDPOINT}
        insecure: false
        secret_access_key: ${AWS_SECRET_ACCESS_KEY}

    runtime_config:
      file: /var/mimir/runtime.yaml

    store_gateway:
      sharding_ring:
        heartbeat_period: 1m
        heartbeat_timeout: 4m
        wait_stability_min_duration: 1m
        tokens_file_path: /data/tokens
        unregister_on_shutdown: false

  alertmanager:
    resources:
      requests:
        cpu: 20m
    persistentVolume:
      enabled: true
      size: 5Gi
  compactor:
    resources:
      requests:
        cpu: 20m
    persistentVolume:
      enabled: true
      size: 5Gi
  distributor:
    resources:
      requests:
        cpu: 20m
  ingester:
    replicas: 2
    zoneAwareReplication:
      enabled: false
    resources:
      requests:
        cpu: 20m
    persistentVolume:
      enabled: true
      size: 5Gi
  overrides_exporter:
    resources:
      requests:
        cpu: 20m
  querier:
    replicas: 1
    resources:
      requests:
        cpu: 20m
  query_frontend:
    resources:
      requests:
        cpu: 20m
  query_scheduler:
    replicas: 1
    resources:
      requests:
        cpu: 20m
  ruler:
    resources:
      requests:
        cpu: 20m
  store_gateway:
    zoneAwareReplication:
      enabled: false
    resources:
      requests:
        cpu: 20m
    persistentVolume:
      enabled: true
      size: 5Gi
  minio:
    enabled: false
  rollout_operator:
    resources:
      requests:
        cpu: 20m

tempo:
  # -- Deploy Tempo if enabled.  See [upstream readme](https://github.com/grafana/helm-charts/blob/main/charts/tempo-distributed/README.md#values) for full values reference.
  enabled: true
  extraEnvFrom:
    - secretRef:
        name: s3-bucket-credentials
  storage:
    backend: s3
    s3:
      endpoint: s3.us-central-1.wasabisys.com
      region: us-central-1
      bucket_name: rye-ninja-tempo

  ingester:
    replicas: 1